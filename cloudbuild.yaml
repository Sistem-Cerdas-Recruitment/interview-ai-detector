steps:
  - name: "gcr.io/cloud-builders/docker"
    args:
      [
        "build",
        "-t",
        "us-central1-docker.pkg.dev/${PROJECT_ID}/interview-ai-detector/model-prediction",
        "./core-model-prediction",
      ]

  - name: "gcr.io/google.com/cloudsdktool/cloud-sdk"
    entrypoint: "bash"
    args:
      - "-c"
      - |
        MODEL_ID=$(gcloud ai models upload \
          --region="us-central1" \
          --container-ports=8080 \
          --container-image-uri="gcr.io/${PROJECT_ID}/interview-ai-detector/model-prediction:latest" \
          --container-predict-route="/predict" \
          --container-health-route="/health" \
          --display-name="interview-ai-detector-model" \
          --format="value(model)")
        echo MODEL_ID > /workspace/model_id.txt

  - name: "gcr.io/google.com/cloudsdktool/cloud-sdk"
    entrypoint: "bash"
    args:
      - "-c"
      - |
        ENDPOINT_ID=$(gcloud ai endpoints create \
          --region="us-central1" \
          --display-name="interview-ai-detector-endpoint" \
          --format="value(name)")
        echo ENDPOINT_ID > /workspace/endpoint_id.txt

  - name: "gcr.io/google.com/cloudsdktool/cloud-sdk"
    entrypoint: "bash"
    args:
      - "-c"
      - |
        gcloud ai endpoints deploy-model "${cat /workspace/endpoint_id.txt}" \
          --region="us-central1" \
          --model="${cat /workspace/model_id.txt}" \
          --display-name="interview-ai-detector-deployment" \
          --machine-type="n1-standard-4" \
          --accelerator="count=1,type=nvidia-tesla-t4" \
          --service-account="vertex-ai-user-managed-sa@steady-climate-416810.iam.gserviceaccount.com"

images:
  - "us-central1-docker.pkg.dev/${PROJECT_ID}/interview-ai-detector/model-prediction"
